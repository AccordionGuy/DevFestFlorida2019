{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A first look at data science tools\n",
    "![Fortune 500](./images/fortune500.jpg)\n",
    "\n",
    "Jupyter notebooks can do a lot with plain ol’ Python, but what makes Python powerful is the litany of libraries that you can import. Let’s make use of a couple the most often-used ones for data science.\n",
    "\n",
    "### Pandas\n",
    "![Kung fu Pandas](./images/fortune500-pandas.jpg)\n",
    "\n",
    "**Pandas** is one of the most useful Python tools in a data scientist’s toolbelt. It features powerful classes and methods for data manipulation and analysis, offering data structures and operations for manipulating numerical tables and time series. Think of it as Excel for data scientists.\n",
    "\n",
    "Its name is derived from “panel data”, an econometrics term for data sets that include observations over multiple time periods for the same individuals.\n",
    "\n",
    "### Matplotlib\n",
    "![Matplotlib](./images/fortune500-matplotlib.jpg)\n",
    "\n",
    "**Matplotlib** is short for *Math Plotting Library*, and it can produce various kinds of graphs and plots, including line graphs, scatter plots, bar graphs, histograms, and all sorts of other charts that are useful for visualizing data.\n",
    "\n",
    "### Seaborn\n",
    "![Seaborn](./images/fortune500-seaborn.jpg)\n",
    "\n",
    "**Seaborn** is a library for making statistical graphs. It’s built on top of Matplotlib and builds on Pandas.\n",
    "\n",
    "Let’s import them!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "sns.set(style=\"darkgrid\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the data from the .csv file into a `DataFrame`\n",
    "Pandas’ `read_csv()` method imports .csv-formatted data. We’ll use it to read the contents of **fortune500.csv** into a `DataFrame` object named `df`.\n",
    "\n",
    "A `DataFrame` is a 2D table with rows and columns — think of it as your data science Excel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CSV_FILE_LOCATION = 'data/fortune500.csv'\n",
    "# CSV_FILE_LOCATION = 'https://raw.githubusercontent.com/AccordionGuy/DevFestFlorida2019/master/data/fortune500.csv'\n",
    "\n",
    "df = pd.read_csv(CSV_FILE_LOCATION)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Investigate the data set\n",
    "`DataFrame` has a method called `head()` that prints the first few rows of the table, nicely formatted.\n",
    "\n",
    "It’s useful for confirming that the data loaded properly and that you’ve got the right data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you might have already inferred `DataFrame` also has a method called `tail()`, which prints the last few rows of the table, just as nicely formatted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rename the columns\n",
    "Let’s rename the columns so that they’re easier to refer to it code. We can do this by redfining the `DataFrame`’s `columns` property, which is a list of strings that define the column names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns = ['year', 'rank', 'company', 'revenue', 'profit']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let’s make sure that our changes were made:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How many rows in the `DataFrame`?\n",
    "Python’s `len()` function is used to return the length of all manner of Python objects, including `DataFrame`s, where it returns the number of rows in the table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What are the column data types?\n",
    "`DataFrame`’s `dtypes` method prints out a list of the columns in the table and their data types.\n",
    "\n",
    "Let’s take a look..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What's up with the `profit` column?\n",
    "![Incomplete data](./images/fortune500-incomplete_data.jpg)\n",
    "\n",
    "The **profit** column’s type doesn’t look quite right. Like **revenue**, it’s an amount of money, and should be the same type: `float64`.\n",
    "\n",
    "Let’s see why this isn’t the case. Let’s create `non_numeric_profits`, a `Series` that for each row, specifies if the **profit** column does or doesn’t contain any numeric characters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "non_numeric_profits = df.profit.str.contains('[^0-9.-]')\n",
    "print(non_numeric_profits)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the `print()` function is kind enough to cut out most of the middle 25,000 or so lines.\n",
    "\n",
    "Most of the values are `False`, but you’ll see that for row **25485**, the value is `True`. That’s one row where there isn’t a numeric value in the **profit** column.\n",
    "\n",
    "What *is* that value? We can find out by using `DataFrame`’s `iloc` method, which you can use to get a row or rows by their integer index:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.iloc[25485]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Can we see a table of just the rows with the missing `profit` values?\n",
    "Yes, and we can do it by using `DataFrame`’s `loc` method, which accesses a group of rows by labels or a boolean array.\n",
    "\n",
    "Remember, we already have a boolean array, `non_numeric_profits`, an array with one element for each `DataFrame` row, each element specifying whether or not its row contains a non-numeric value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[non_numeric_profits]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How many `profit` values are missing?\n",
    "Once again, Python’s `len()` function comes in handy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df.profit[non_numeric_profits])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "369 rows out of 25485 is pretty small. What percentage of the entire set does it represent?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"{round(369 / 25485 * 100, 2)}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It’s about 1,5% — small, but not completely inconsequential. \n",
    "\n",
    "If the rows with missing `profit` values are are roughly uniformly distributed over the years, the easiest solution would just be to remove them. Let's see if they *are* uniformly distributed..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bin_sizes, _, _ = plt.hist(df.year[non_numeric_profits], \n",
    "                           bins=range(1955, 2006))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is why we use graphs — as visual creatures, they reveal things to us that we might never catch if we simply looked at tables of numbers.\n",
    "\n",
    "We can see that no single year has more than 25 missing `profit` values. With 500 data points per year, removing these values would account for less than 4% of the data for the years with the most missing data. \n",
    "\n",
    "With the notable exception of the ’90s “grunge era”, most years have fewer than half the missing values of the peak. For our purposes, we’ll say that this is acceptable and remove these rows. We’ll also need to convert the values in the `profit` column from strings (actually, type `object`) to numbers. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove the rows with non-numeric values in the \"profit\" column.\n",
    "cleaned_up_df = df.loc[~non_numeric_profits]\n",
    "\n",
    "# Convert the values in the \"profit\" column from strings to numbers.\n",
    "cleaned_up_df.profit = cleaned_up_df.profit.apply(pd.to_numeric)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's make sure it worked:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(cleaned_up_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That’s fewer rows than the original.\n",
    "\n",
    "Let's check those types again:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_up_df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Let's plot!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "group_by_year = cleaned_up_df.loc[:, ['year', 'revenue', 'profit']].groupby('year')\n",
    "avgs = group_by_year.mean()\n",
    "x = avgs.index\n",
    "y1 = avgs.profit\n",
    "\n",
    "def plot(x, y, ax, title, y_label):\n",
    "    ax.set_title(title)\n",
    "    ax.set_ylabel(y_label)\n",
    "    ax.plot(x, y)\n",
    "    ax.margins(x=0, y=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "plot(x, y1, ax, 'Increase in mean Fortune 500 company profits from 1955 to 2005', 'Profit (millions)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It looks like exponential growth, but with huge dips. They must correspond to the early 1990s recession and the dot-com bubble. It's pretty interesting to see that in the data. \n",
    "\n",
    "Note that profits recovered to even higher levels after each dip. Perhaps revenues can tell us more."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y2 = avgs.revenue\n",
    "fig, ax = plt.subplots()\n",
    "plot(x, y2, ax, 'Increase in mean Fortune 500 company revenues from 1955 to 2005', 'Revenue (millions)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That adds another side to the story. Revenues were no way nearly as badly hit, that's some great accounting work from the finance departments.\n",
    "\n",
    "Is there a way to superimpose the standard deviations over these profit and revenue graphs?\n",
    "\n",
    "<img src=\"img/stack-overflow.jpg\">\n",
    "\n",
    "Stack Overflow to the rescue! There's code that does just that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_with_std(x, y, stds, ax, title, y_label):\n",
    "    ax.fill_between(x, y - stds, y + stds, alpha=0.2)\n",
    "    plot(x, y, ax, title, y_label)\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(ncols=2)\n",
    "title = 'Increase in mean and std Fortune 500 company %s from 1955 to 2005'\n",
    "stds1 = group_by_year.std().profit.values\n",
    "stds2 = group_by_year.std().revenue.values\n",
    "plot_with_std(x, y1.values, stds1, ax1, title % 'profits', 'Profit (millions)')\n",
    "plot_with_std(x, y2.values, stds2, ax2, title % 'revenues', 'Revenue (millions)')\n",
    "fig.set_size_inches(14, 4)\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's staggering, the standard deviations are huge. Some Fortune 500 companies make billions while others lose billions, and the risk has increased along with rising profits over the years. Perhaps some companies perform better than others; are the profits of the top 10% more or less volatile than the bottom 10%?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
